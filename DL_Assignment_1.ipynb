{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCz7LgDxulcavtULoCB40m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scarfaced007/CNN-DL/blob/main/DL_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u5h4Pk7lgEje"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ8wKXFMki9A",
        "outputId": "49cba950-845a-4ee4-ff0c-214463fd341a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18(weights=None)\n",
        "\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model.maxpool = nn.Identity()\n",
        "model.fc = nn.Linear(512, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)"
      ],
      "metadata": {
        "id": "IhaiyGRGkmVI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "history = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    train_acc = 100. * correct / total\n",
        "    history['train_loss'].append(running_loss / len(train_loader))\n",
        "    history['train_acc'].append(train_acc)\n",
        "\n",
        "    model.eval()\n",
        "    test_correct, test_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    test_acc = 100. * test_correct / test_total\n",
        "    history['test_acc'].append(test_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {history['train_loss'][-1]:.4f} | \"f\"Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkawbOPAksmR",
        "outputId": "6988be2e-cf51-4ff4-c14d-f8340173fb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25 | Loss: 2.0121 | Train Acc: 29.57% | Test Acc: 43.63%\n",
            "Epoch 2/25 | Loss: 1.3156 | Train Acc: 52.18% | Test Acc: 54.72%\n",
            "Epoch 3/25 | Loss: 0.9797 | Train Acc: 65.22% | Test Acc: 64.31%\n",
            "Epoch 4/25 | Loss: 0.7531 | Train Acc: 73.29% | Test Acc: 72.54%\n",
            "Epoch 5/25 | Loss: 0.5943 | Train Acc: 79.35% | Test Acc: 74.63%\n",
            "Epoch 6/25 | Loss: 0.4885 | Train Acc: 82.99% | Test Acc: 75.00%\n",
            "Epoch 7/25 | Loss: 0.4165 | Train Acc: 85.50% | Test Acc: 78.09%\n",
            "Epoch 8/25 | Loss: 0.3669 | Train Acc: 87.30% | Test Acc: 78.99%\n",
            "Epoch 9/25 | Loss: 0.3195 | Train Acc: 88.87% | Test Acc: 78.73%\n",
            "Epoch 10/25 | Loss: 0.2943 | Train Acc: 89.80% | Test Acc: 79.65%\n",
            "Epoch 11/25 | Loss: 0.2542 | Train Acc: 91.19% | Test Acc: 79.74%\n",
            "Epoch 12/25 | Loss: 0.2378 | Train Acc: 91.70% | Test Acc: 76.24%\n",
            "Epoch 13/25 | Loss: 0.2093 | Train Acc: 92.70% | Test Acc: 77.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.title('Baseline: Training Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['train_acc'], label='Train Acc')\n",
        "plt.plot(history['test_acc'], label='Test Acc')\n",
        "plt.title('Baseline: Accuracy Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "isg-q1GMkzI-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def get_high_confidence_failures(model, loader, threshold=0.85, num_images=5):\n",
        "    \"\"\"\n",
        "    Finds images where the model is incorrect but predicts with high confidence.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    failures = []\n",
        "    classes = ('Plane', 'Car', 'Bird', 'Cat', 'Deer',\n",
        "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n",
        "\n",
        "    # Normalization constants (to un-normalize images for plotting)\n",
        "    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1).to(device)\n",
        "    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Get probabilities (Softmax)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            conf, preds = torch.max(probs, dim=1)\n",
        "\n",
        "            # Find errors: Prediction != Label AND Confidence > Threshold\n",
        "            wrong_indices = (preds != labels) & (conf > threshold)\n",
        "            failure_idx = torch.nonzero(wrong_indices, as_tuple=True)[0]\n",
        "\n",
        "            if len(failure_idx) > 0:\n",
        "                for idx in failure_idx:\n",
        "                    if len(failures) >= num_images:\n",
        "                        return failures\n",
        "\n",
        "                    # Un-normalize image for visualization\n",
        "                    img = inputs[idx] * std + mean\n",
        "                    img = torch.clamp(img, 0, 1) # Ensure pixel values are valid [0,1]\n",
        "\n",
        "                    failures.append({\n",
        "                        'image': img.cpu(),\n",
        "                        'true': classes[labels[idx].item()],\n",
        "                        'pred': classes[preds[idx].item()],\n",
        "                        'conf': conf[idx].item()\n",
        "                    })\n",
        "    return failures\n",
        "\n",
        "def plot_failures(failures):\n",
        "    \"\"\"\n",
        "    Plots the collected failure cases.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    for i, fail in enumerate(failures):\n",
        "        ax = plt.subplot(1, len(failures), i + 1)\n",
        "\n",
        "        # Convert tensor (C, H, W) -> numpy (H, W, C)\n",
        "        img_np = fail['image'].permute(1, 2, 0).numpy()\n",
        "\n",
        "        plt.imshow(img_np)\n",
        "        plt.title(f\"True: {fail['true']}\\nPred: {fail['pred']}\\nConf: {fail['conf']:.2f}\",\n",
        "                  color='red', fontsize=12)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Execution ---\n",
        "print(\"Searching for high-confidence failures...\")\n",
        "# Note: If no failures are found, try lowering the threshold (e.g., to 0.80)\n",
        "failure_cases = get_high_confidence_failures(model, test_loader, threshold=0.90, num_images=5)\n",
        "\n",
        "if len(failure_cases) > 0:\n",
        "    print(f\"Found {len(failure_cases)} high-confidence failures:\")\n",
        "    plot_failures(failure_cases)\n",
        "else:\n",
        "    print(\"No failures found above the threshold. Your model might be too accurate or calibrated!\")"
      ],
      "metadata": {
        "id": "ViNi23aBwX9n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}